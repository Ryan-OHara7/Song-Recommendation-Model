{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3abc75-3ca2-4aae-b4e4-56bbca8addeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e77f47f-2f4f-40c1-81ad-6c9dd2eabc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set file path (change to fit your files)\n",
    "df_combined_no_embeddings_path = r'combined_df_no_embeddings.csv'\n",
    "\n",
    "df_combined_no_embeddings = pd.read_csv(df_combined_no_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d6e45b-c4a1-4e43-92cf-2ee1052c847f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>BPM</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Acoustic</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Loud</th>\n",
       "      <th>Clean_Lyrics</th>\n",
       "      <th>...</th>\n",
       "      <th>Subgenre_rock 90s</th>\n",
       "      <th>Subgenre_rock alternative</th>\n",
       "      <th>Subgenre_soul</th>\n",
       "      <th>Subgenre_soul 60s</th>\n",
       "      <th>Subgenre_soul 70s</th>\n",
       "      <th>Subgenre_soul 80s</th>\n",
       "      <th>Subgenre_soul disco</th>\n",
       "      <th>Subgenre_soul rnb</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stretch You Out (feat. A Boogie wit da Hoodie)</td>\n",
       "      <td>Summer Walker,A Boogie Wit da Hoodie</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.76</td>\n",
       "      <td>get london da track niggas insecure claim enou...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['get', 'london', 'da', 'track', 'niggas', 'in...</td>\n",
       "      <td>[-5.49920015e-02 -4.24173214e-02  1.20421372e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On Melancholy Hill</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.80</td>\n",
       "      <td>melancholy hill good side consumerism like muc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['melancholy', 'hill', 'good', 'side', 'consum...</td>\n",
       "      <td>[-1.40985716e-02 -4.45414186e-02  1.11462869e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHO CARES?</td>\n",
       "      <td>Rex Orange County</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.80</td>\n",
       "      <td>mmmm mmmm mmmm mmmm first time try free doubt ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['mmmm', 'mmmm', 'mmmm', 'mmmm', 'first', 'tim...</td>\n",
       "      <td>[-1.85818132e-03 -3.64763662e-02  1.47965446e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solid</td>\n",
       "      <td>Ashford &amp; Simpson</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.56</td>\n",
       "      <td>love sake mistake oh forgave soon learn trust ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['love', 'sake', 'mistake', 'oh', 'forgave', '...</td>\n",
       "      <td>[-1.36662908e-02 -1.14702322e-02  1.19016811e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREAK MY SOUL</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.84</td>\n",
       "      <td>'bout explode take load bend bust open ya make...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[\"'bout\", 'explode', 'take', 'load', 'bend', '...</td>\n",
       "      <td>[-5.63979559e-02 -5.03409989e-02  1.03356943e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Song  \\\n",
       "0  Stretch You Out (feat. A Boogie wit da Hoodie)   \n",
       "1                              On Melancholy Hill   \n",
       "2                                      WHO CARES?   \n",
       "3                                           Solid   \n",
       "4                                   BREAK MY SOUL   \n",
       "\n",
       "                                 Artist  Popularity       BPM     Dance  \\\n",
       "0  Summer Walker,A Boogie Wit da Hoodie        0.50  0.317647  0.623529   \n",
       "1                              Gorillaz        0.80  0.417647  0.682353   \n",
       "2                     Rex Orange County        0.35  0.217647  0.835294   \n",
       "3                     Ashford & Simpson        0.45  0.305882  0.823529   \n",
       "4                               Beyoncé        0.55  0.388235  0.682353   \n",
       "\n",
       "     Energy  Acoustic     Happy  Loud  \\\n",
       "0  0.494737  0.252525  0.231579  0.76   \n",
       "1  0.726316  0.000000  0.578947  0.80   \n",
       "2  0.242105  0.595960  0.589474  0.80   \n",
       "3  0.442105  0.272727  0.978947  0.56   \n",
       "4  0.884211  0.060606  0.863158  0.84   \n",
       "\n",
       "                                        Clean_Lyrics  ...  Subgenre_rock 90s  \\\n",
       "0  get london da track niggas insecure claim enou...  ...                0.0   \n",
       "1  melancholy hill good side consumerism like muc...  ...                0.0   \n",
       "2  mmmm mmmm mmmm mmmm first time try free doubt ...  ...                0.0   \n",
       "3  love sake mistake oh forgave soon learn trust ...  ...                0.0   \n",
       "4  'bout explode take load bend bust open ya make...  ...                0.0   \n",
       "\n",
       "   Subgenre_rock alternative  Subgenre_soul  Subgenre_soul 60s  \\\n",
       "0                        0.0            0.0                0.0   \n",
       "1                        0.0            0.0                0.0   \n",
       "2                        0.0            0.0                0.0   \n",
       "3                        0.0            0.0                0.0   \n",
       "4                        0.0            0.0                0.0   \n",
       "\n",
       "   Subgenre_soul 70s  Subgenre_soul 80s  Subgenre_soul disco  \\\n",
       "0                0.0                0.0                  0.0   \n",
       "1                0.0                0.0                  0.0   \n",
       "2                0.0                0.0                  0.0   \n",
       "3                0.0                1.0                  0.0   \n",
       "4                0.0                0.0                  0.0   \n",
       "\n",
       "   Subgenre_soul rnb                                             Tokens  \\\n",
       "0                1.0  ['get', 'london', 'da', 'track', 'niggas', 'in...   \n",
       "1                0.0  ['melancholy', 'hill', 'good', 'side', 'consum...   \n",
       "2                0.0  ['mmmm', 'mmmm', 'mmmm', 'mmmm', 'first', 'tim...   \n",
       "3                0.0  ['love', 'sake', 'mistake', 'oh', 'forgave', '...   \n",
       "4                0.0  [\"'bout\", 'explode', 'take', 'load', 'bend', '...   \n",
       "\n",
       "                                          Embeddings  \n",
       "0  [-5.49920015e-02 -4.24173214e-02  1.20421372e-...  \n",
       "1  [-1.40985716e-02 -4.45414186e-02  1.11462869e-...  \n",
       "2  [-1.85818132e-03 -3.64763662e-02  1.47965446e-...  \n",
       "3  [-1.36662908e-02 -1.14702322e-02  1.19016811e-...  \n",
       "4  [-5.63979559e-02 -5.03409989e-02  1.03356943e-...  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_no_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac371ae-3684-422a-a3e6-00d4f8dd2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using word2vec this week (from week 7 notebook)\n",
    "\n",
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-twitter-200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae782f06-1e4b-4939-90ab-1c9224534879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that converts a list of tokenized words into a single (fixed length) vector using the glove-twitter-200 model\n",
    "def get_embedding_twitter(tokens, model):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70515b4c-edf0-406c-898f-b9463278e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a column called 'Twitter_Embeddings\" in all three of the dataframes/datasets by applying the get_embedding_twitter() function to the tokens list\n",
    "\n",
    "combined_df['Twitter_Embeddings'] = combined_df['Tokens'].apply(lambda tokens: get_embedding_twitter(tokens, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8145a-776d-4e4b-ab45-c345073a035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allows us to work with the vector numerically\n",
    "def str_to_embedding(s):\n",
    "    # Remove [ and ] characters\n",
    "    s = s.strip('[]')\n",
    "    # Split by spaces and convert each to float\n",
    "    return np.array([float(x) for x in s.split()])\n",
    "\n",
    "# Example usage:\n",
    "embedding_str = \"[-5.49920015e-02 -4.24173214e-02 1.20421372e-02]\"\n",
    "embedding_vector = str_to_embedding(embedding_str)\n",
    "print(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fd8c4-7a0e-4276-b6aa-d701ff5d93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the string in 'Embeddings' column into numpy array using the above function\n",
    "combined_df['Embeddings'] = combined_df['Embeddings'].apply(str_to_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3e3e2-428d-469f-b624-97551fa1dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c28c79-23f1-4be9-85e1-194c659e23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('~/Downloads/combined_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
